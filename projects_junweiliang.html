<html>
<head>
	<meta  http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=0" />
	<link rel="stylesheet" type="text/css" href="utils/bootstrap.min.css"/>
  <script language="javascript" src="utils/jquery.min.js"></script>
	<script language="javascript" src="utils/bootstrap.min.js"></script>
  <!-- -->
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css"/>
	<link rel="stylesheet" type="text/css" href="utils/cssReset.css"/>
  <link rel="stylesheet" type="text/css" href="utils/css_layout.css"/>
	<title>Prof. Junwei Liang / 梁俊卫</title>
  <!-- 搜索引擎优化stuff -->
	<meta name="description"
    content="Academic website for Junwei Liang. Dr. Junwei Liang is currently a tenure-track Assistant Professor at The Hong Kong University of Science and Technology (Guangzhou). He was a senior researcher at Tencent Youtu Lab working on cutting-edge computer vision research and applications. Prior to that, he received his Ph.D. degree from Carnegie Mellon University, working with Prof. Alexander Hauptmann. He is the recipient of Baidu Scholarship and Yahoo Fellowship, and awarded Rising Star Award at the World AI Conference in 2020. He is the winner of several public safety video analysis competition, including ASAPS and TRECVID ActEV. His work has helped and reported by major news agencies like the Washington Post and New York Times. His research interests include human trajectory forecasting, action recognition, and large-scale computer vision and video analytics in general. His mission: develop AI technologies for social good.">
	<meta name="keywords" content="Junwei Liang,CMU,HKUST,HKUST-GZ,Professor,computer vision,PhD,梁俊卫,Carnegie Mellon University,The Hong Kong University of Science and Technology">

</head>
<body>
<div id="sidebar">
  <img class='me' src="resources/me.jpeg"></img>
  <br/>
  <div class="info">
    <h2 class="name">Prof. Junwei Liang</h2>
    <h2 class="name_chinese">梁俊卫</h2>
    <h2 class="email">junweiliang1114@gmail.com</h2>
    <h2 class="email">junweiliang@hkust-gz.edu.cn</h2>
    <h2 class="email">HKUST (Guangzhou) / Office: E4-304</h2>
    <h2 class="link">
      <a style="font-size: 14px; color: yellow; font-weight: bold;" href="https://scholar.google.com/citations?hl=en&user=bMedjfUAAAAJ">Google Scholar</a>
    </h2>
    <h2 class="link">
      <a href="https://www.semanticscholar.org/author/Junwei-Liang/1915796">[Semantic Scholar]</a>
      <a href="https://www.researchgate.net/profile/Junwei_Liang3">[Research Gate]</a>
    </h2>
    <h2 class="link">
      <a href="https://github.com/JunweiLiang">[Github]</a>
      <a href="https://paperswithcode.com/search?q=author%3AJunwei+Liang">[PaperWithCode]</a>
    </h2>
    <h2 class="link">
      <a href="https://www.zhihu.com/people/junwei-liang-50">[知乎]</a>
      <a href="https://www.youtube.com/channel/UC-z7ZWp8Rbu2xhxnbAL_bRQ">[Youtube]</a>
      <a href="https://space.bilibili.com/1746376957/">[B站]</a>
    </h2>
    <h2 class="link">
      <a href="https://www.linkedin.com/in/junweiliang/">[LinkedIn]</a>
      <a href="https://twitter.com/JunweilLiang">[Twitter]</a>
      <a href="https://www.xiaohongshu.com/user/profile/62c3a783000000001b02b099">[小红书]</a>
    </h2>

    <!--
    <a class="quickLink" href="https://medium.com/@junweil">
      <img class='medium' style="" src="resources/medium.png"></img>
    </a>
    <a class="quickLink" href="https://dblp.org/pers/hd/l/Liang_0001:Junwei">
      <img class='dblp' style="height:20px" src="resources/dblp.png"></img>
    </a>
    <a class="quickLink" href="http://aminer.cn/profile/junwei-liang/562cb48c45cedb3398c9e13b">
      <img class='aminer' style="height:20px;width: 50px;margin-top:4px" src="resources/aminer.png"></img>
    </a>
    <a class="quickLink" href="https://g.co/kgs/gTWf5W">
      <img class='aminer' name="Google knowledge graph" style="height:30px;width: 30px;margin-top:0px" src="resources/gkg.png"></img>
    </a>-->

  </div>
  <div id="navigation">
    <a class="nav_item" href="./index.html">
      <i class="icon icon-home icon-white"></i> &nbsp; About
    </a>
    <a class="nav_item" href="./projects.html#projects">
      <i class="icon icon-th-large icon-white"></i> &nbsp; Projects
    </a>
    <a class="nav_item" href="./projects.html#publications">
      <i class="icon icon-file icon-white"></i> &nbsp; Publications
    </a>
    <a class="nav_item" href="./teaching.html#teaching">
      <i class="icon icon-user icon-white"></i> &nbsp; Teaching / Talks
    </a>
    <a class="nav_item" href="./index.html#awards">
      <i class="icon icon-bookmark icon-white"></i> &nbsp; Honors / Awards
    </a>
    <a class="nav_item" href="./index.html#media">
      <i class="icon icon-volume-up icon-white"></i> &nbsp; Selected Media
    </a>
    <a class="nav_item" href="./awesome.html">
      <i class="icon icon-list icon-white"></i> &nbsp; Awesome Lists
    </a>
    <a class="nav_item" href="./letter.html">
      <i class="icon icon-pencil icon-white"></i> &nbsp; Letter
    </a>

  </div>
</div>

<style type="text/css">
  #main{
    background: #f7f7f7;
  }
  #main > div.publications > ol > li{
    background: white;
    box-shadow: 2px 5px 5px #c9c9c9;
    margin-bottom: 10px;
    padding: 20px;
  }
  #main div.img{
    padding: 20px;
    text-align: center;
    padding-right: 150px;
  }
  #main div.img > div.img_caption{
    font-weight: 450;
    font-size: 1.1em;
    line-height: 40px;
  }
</style>


<div id="main">

  <div class="title">
    <a class="title_link" id="projects" href="#projects">Projects</a>
  </div>

  <div class="content">
    See our precognition lab website for a <span style="font-weight: bold;"><a href="https://precognition.team/projects.html#roadmap">research roadmap</a></span>
    and <span style="font-weight: bold;"><a href="https://precognition.team/index.html#publications">demos</a></span>.
    <br/>
    Here are on-going or finished research grants:
    <ul>
      <li>
        国自然青年基金，2024 (PI)
      </li>
      <li>
        广州市校（院）企联合资助项目，2024 (PI)
      </li>
      <li>
        广州市基础与应用基础研究专题（青年博士“启航”项目），2024 (PI)
      </li>
      <li>
        美团深圳机器人研究院课题，2024 (PI)
      </li>
      <li>
        香港科技大学（广州）本科生暑期科研项目x2，2024 (PI)
      </li>
      <li>
        香港科技大学（广州）低空经济项目，2024 (Co-PI)
      </li>
      <li>
        国家科技部重点研发计划，2024 (参与)
      </li>
    </ul>


  </div>


  <div class="title">
    <a class="title_link" id="publications" href="#publications">Publications</a>
  </div>

  <div class="content publications">
    <ol>
      For more research, please visit the <a href="https://scholar.google.com/citations?user=fONA0roAAAAJ&hl=zh-CN">Google Scholar</a>.
      
      <!-- TaskWeave-CVPR2024 -->
      <li>
        <div class="imgblock"><img src="camera_ready/cvpr2024_taskweave.gif"></img></div>
        <span class="title">Task-Driven Exploration: Decoupling and Inter-Task Feedback for Joint Moment Retrieval and Highlight Detection
        </span>
        <div class="info text-success italic"><span style="font-weight:bold">Jin Yang</span>, Ping Wei, Huan Li, Ziyang Ren</div>
        <div class="info"><span class="label label-info">CVPR 2024</span></div>
        <div class="stuff">
          <a class="" href="https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Task-Driven_Exploration_Decoupling_and_Inter-Task_Feedback_for_Joint_Moment_Retrieval_CVPR_2024_paper.pdf" target="_blank">Paper/</a>
          <a class="" href="https://scholar.googleusercontent.com/scholar.bib?q=info:qXMtBN-M7s0J:scholar.google.com/&output=citation&scisdr=ClESQuHWEPLz9Cfnm0M:AFWwaeYAAAAAZpPhg0OYCWvkRyYZ502bUCU-WuQ&scisig=AFWwaeYAAAAAZpPhg0gKOWacjfJqUQIzEuoL8qI&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">BibTex/</a>
          <a class="" href="https://github.com/EdenGabriel/TaskWeave" target="_blank">Code/</a>
          <!-- TODO -->
          <a class="" href="https://github.com/EdenGabriel/TaskWeave" target="_blank">Releated Project</a>
        </div>
        <div style="clear:both"></div>
      </li>

      <!-- TFFormer TCSVT2024-->
      <li>
        <!-- <div class="imgblock" style="height:200px"><img src="camera_ready/transgmc_tmm23.gif"></img></div> -->
        <div class="imgblock"><img src="camera_ready/tcsvt2024_tfformer.png"></img></div>
        <span class="title">Cross Time-Frequency Transformer for Temporal Action Localization
        </span>
        <div class="info text-success italic"><span style="font-weight:bold">Jin Yang</span>, Ping Wei, Nanning Zheng</div>
        <div class="info"><span class="label label-info">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT 2024)</span></div>
        <div class="stuff">
          <a class="" href="https://ieeexplore.ieee.org/document/10290953" target="_blank">Paper/</a>
          <a class="" href="camera_ready/tcsvt2024_tfformer.bib" target="_blank">BibTex/</a>
          <a class="" href="https://www.youtube.com/watch?v=XN7pfajhlxc" target="_blank">Demo Video/</a>
          <a class="" href="https://github.com/EdenGabriel/TFFormer" target="_blank">Code</a>
        </div>
        <div style="clear:both"></div>
      </li>

      <!-- TransGMC TMM2023 -->
      <li>
        <div class="imgblock"><img src="camera_ready/tmm23_transgmc.gif"></img></div>
        <span class="title">Gated Multi-Scale Transformer for Temporal Action Localization
        </span>
        <div class="info text-success italic"><span style="font-weight:bold">Jin Yang</span>, Ping Wei, Ziyang Ren, Nanning Zheng</div>
        <div class="info"><span class="label label-info">IEEE Transactions on Multimedia (TMM 2023)</span></div>
        <div class="stuff">
          <a class="" href="https://ieeexplore.ieee.org/abstract/document/10336518" target="_blank">Paper/</a>
          <a class="" href="camera_ready/tmm23_transgmc.bib" target="_blank">BibTex/</a>
          <a class="" href="https://www.youtube.com/watch?v=rZAn0A5jLb8" target="_blank">Demo Video/</a>
          <a class="" href="https://github.com/EdenGabriel/TransGMC" target="_blank">Code</a>
        </div>
        <div style="clear:both"></div>
      </li>

      <!-- TSMC2022 -->
      <li>
        <div class="imgblock"><img src="camera_ready/SAC-evaluation.gif"></img></div>
        <span class="title">Deep reinforcement learning with a stage incentive mechanism of dense reward for robotic trajectory planning
        </span>
        <!-- <div class="info text-muted italic">Gang Peng, <span style="font-weight:bold">Jin Yang<sup>*</sup></span>, Xinde Li, Mohammad Omar Khyam ( <sup>*</sup> student first author)</div>
         -->
         <div class="info text-success italic">Gang Peng, <span style="font-weight:bold">Jin Yang<sup>*</sup></span>, Xinde Li, Mohammad Omar Khyam ( <sup>*</sup> student first author)</div>
        <div class="info"><span class="label label-info">IEEE Transactions on Systems, Man, and Cybernetics: Systems (TSMC 2022)</span></div>
        <div class="stuff">
          <a class="" href="https://ieeexplore.ieee.org/abstract/document/10004017" target="_blank">Paper/</a>
          <a class="" href="https://scholar.googleusercontent.com/scholar.bib?q=info:PGn5_5FngQkJ:scholar.google.com/&output=citation&scisdr=ClESQuHWEPLz9CfyR2s:AFWwaeYAAAAAZpP0X2tF4XXw2LHAttg95EykYFU&scisig=AFWwaeYAAAAAZpP0X0gIDJQhgRLmi81MDNnWBOs&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">BibTex/</a>
          <!-- TODO -->
          <a class="" href="https://www.youtube.com/watch?v=XN7pfajhlxc" target="_blank">Related Project</a>
        </div>
        <div style="clear:both"></div>
      </li>

      <!-- ICCAR2021 -->
      <li>
        <div class="imgblock"><img src="camera_ready/ICCAR2021.png" style="transform: scale(0.9);"></img></div>
        <span class="title">DDPG with meta-learning-based experience replay separation for robot trajectory planning
        </span>
        <div class="info text-success italic"><span style="font-weight:bold">Jin Yang</span>, Gang Peng</div>
        <div class="info"><span class="label label-info">ICCAR 2021</span></div>
        <div class="info"><span class="text-error">Oral presentation</span></div>
        <div class="stuff">
          <a class="" href="https://ieeexplore.ieee.org/abstract/document/9463493" target="_blank">Paper/</a>
          <a class="" href="https://scholar.googleusercontent.com/scholar.bib?q=info:RBmtz3m3i6AJ:scholar.google.com/&output=citation&scisdr=ClESQuHWEPLz9Cf3fhY:AFWwaeYAAAAAZpPxZhadsiathU0TRYs1ev-vKCw&scisig=AFWwaeYAAAAAZpPxZmzYJK0jvv1I6xiEhYJGJtM&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">BibTex/</a>
          <!-- TODO -->
          <a class="" href="https://www.youtube.com/watch?v=XN7pfajhlxc" target="_blank">Related Project</a>
        </div>
        <div style="clear:both"></div>
      </li>


      <!-- reference list term -->
      <!-- <li>
        <div class="imgblock"><img src="camera_ready/msnet.jpg"></img></div>
        <span class="title">MSNet: A Multilevel Instance Segmentation Network for Natural Disaster Damage Assessment in Aerial Videos
        </span>
        <div class="info text-success italic">Xiaoyu Zhu, <span style="font-weight:bold">Junwei Liang</span>, Alexander Hauptmann</div>
        <div class="info"><span class="label label-info">WACV 2021</span> &nbsp;
          <iframe src="https://ghbtns.com/github-btn.html?user=zgzxy001&repo=MSNET&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
        </div>
        <div class="info"><span class="text-error">Reported by CMU news </span></div>
        <div class="stuff">
          <a class="" href="http://openaccess.thecvf.com/content/WACV2021/papers/Zhu_MSNet_A_Multilevel_Instance_Segmentation_Network_for_Natural_Disaster_Damage_WACV_2021_paper.pdf" target="_blank">[Paper]</a>
          <a class="" href="https://www.cmu.edu/news/stories/archives/2020/august/drones-hurricane-damage.html" target="_blank">[CMU News]</a>
          <a class="" href="https://github.com/zgzxy001/MSNET" target="_blank">[Project Page/Code/Model]</a>
        </div>
        <div style="clear:both"></div>
      </li> -->
      <!-- <li>
        <div class="imgblock"  style="height:170px;" ><img src="camera_ready/mm19.gif"></img></div>
        <span class="title">Shooter Localization Using Social Media Videos
        </span>
        <div class="info text-success italic"><span style="font-weight:bold">Junwei Liang</span>, Jay Aronson, Alexander Hauptmann</div>
        <div class="info"><span class="label label-info">ACM Multimedia (MM) 2019</span> <span class="text-error"><br/>(Press coverage:
          <a href="https://pittsburgh.cbslocal.com/2019/11/20/cmu-develops-video-system-locate-mass-shooters/">
            <img class="press" src="resources/cbs.png"></img>
          </a>,
          <a href="https://www.cmu.edu/news/stories/archives/2019/november/system-locates-shooters-using-smartphone-video.html">
            <img class="press" src="resources/cmu.png"></img>
          </a>,

          <a href="https://www.wpxi.com/news/top-stories/shooters-can-be-located-with-smartphone-video-using-new-cmu-developed-tool/1010922936">
            <img class="press" src="resources/wpxi.png"></img>
          </a>,
          <a href="https://www.post-gazette.com/business/tech-news/2019/11/20/Carnegie-Mellon-CMU-develops-cellphone-smartphone-video-system-location-shooter-triangulate/stories/201911200101">
            <img class="press" src="resources/post.png"></img>
          </a>,
          <a href="https://www.dailymail.co.uk/sciencetech/article-7707501/Carnegie-Mellon-aims-end-pro-longed-massacres-locates-active-shooters.html">
            <img class="press" src="resources/dailymail.png"></img>
          </a>,
          <a href="https://gizmodo.com/smartphone-videos-can-now-be-analyzed-and-used-to-pinpo-1839979803">
            <img class="press" src="resources/gizmodo.png"></img>
          </a>,
          <a href="https://www.msn.com/en-us/news/us/researchers-at-carnegie-mellon-university-develop-video-system-to-locate-mass-shooters/ar-BBX3wRA">
            <img class="press" src="resources/msn.png"></img>
          </a>,
          <a href="https://www.techspot.com/news/82881-researchers-develop-system-can-pinpoint-shooter-location-using.html">
            <img class="press" src="resources/techspot.png"></img>
          </a>,
          <a href="https://www.sciencedaily.com/releases/2019/11/191120070712.htm">
            <img class="press" src="resources/science_daily.png"></img>
          </a>,
          <a href="https://gcn.com/articles/2019/11/22/smartphone-shooter-location.aspx">
            <img class="press" src="resources/gcn.png"></img>
          </a>
        )</span> </div>
        <div class="stuff">
          <a class="" href="https://www.cmu.edu/chrs/publications/pdf/shooter-localization-using-social-media-videos.pdf" target="_blank">[Paper]</a>
          <a class="" href="camera_ready/mm19.bib" target="_blank">[BibTex]</a>
          <a class="" href="https://www.youtube.com/watch?v=6q7LqqzrY2I" target="_blank">[Demo Video]</a>
          <a class="" href="https://vera.cs.cmu.edu" target="_blank">[Project Page]</a>
        </div>
        <div style="clear:both"></div>
      </li> -->

    </ol>
  </div>

  <!-- reference past-projects -->
  <!-- <div class="title">
    <a class="title_link" id="past-projects" href="#past-projects">Past Projects</a>
  </div>
  <div class="content">
    <ul>
      <li>
        <span class="title">Public Safety / AI for Social Good [sponsored by <a href="https://www.nist.gov/ctl/pscr/real-time-video-analytics-situation-awareness">NIST</a>] [<a href="https://www.herox.com/ASAPS1/update/3483">ASAPS challenge</a> winner]</span> <div class="float-right time">2017 - 2021</div>
        <div class="info">
          <a href="https://vera.cs.cmu.edu/">Gunshot Detection & Shooter Localization</a>
          <iframe src="https://ghbtns.com/github-btn.html?user=JunweiLiang&repo=VERA_Shooter_Localization&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
        </div>
        <div class="info">
          <a href="https://vera.cs.cmu.edu/VERA_3D_Reconstruction/">3D Event Reconstruction</a>
          <iframe src="https://ghbtns.com/github-btn.html?user=JunweiLiang&repo=VERA_3D_Reconstruction&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
        </div>
        <div class="info">
          <a href="https://aladdin1.inf.cs.cmu.edu/human-rights">Video Analytic Toolkit</a>
        </div>
      </li>
    </ul>
  </div> -->

  <!-- reference review Academic Service -->
  <!-- <div class="title">
    <a class="title_link" id="review" href="#review">Academic Service</a>
  </div>

  <div class="content">
    <ul>
      <li>
        <span class="title">Workshop Organizer</span>
        <div class="info">Open-world Visual Perception Workshop @PRCV 2023 [<a href="https://mp.weixin.qq.com/s/ib9aKBhQhoaAFqZB93F3wQ">link</a>]</div>
        <div class="info">Precognition Workshop @CVPR 2023 [<a href="https://sites.google.com/view/ieeecvf-cvpr2023-precognition">link</a>] [<a href="https://www.youtube.com/watch?v=Z3JhfOp0eGM">CVPR Recording</a>]</div>
      </li>
      <li>
        <span class="title">Journal Reviewer</span>
        <div class="info">IEEE Transactions on Pattern Analysis and Machine Intelligence <span style="font-weight: bold;">(TPAMI)</span></div>
        <div class="info">IEEE Transactions on Image Processing (TIP)</div>
        <div class="info">Pattern Recognition</div>
        <div class="info">Artificial Intelligence Review (AIRE)</div>
        <div class="info">IEEE Transactions on Intelligent Transportation Systems (ITS)</div>
        <div class="info">IEEE Transactions on Multimedia</div>
        <div class="info">IEEE Internet of Things Journal</div>
        <div class="info">IEEE Transactions on Big Data</div>
        <div class="info">IEEE Transactions on Medical Imaging</div>
        <div class="info">IEEE Access</div>
        <div class="info">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</div>
        <div class="info">ACM TOMM</div>
        <div class="info">Neurocomputing</div>
        <div class="info">Nature Scientific Reports</div>
        <div class="info">Information Sciences</div>
        <div class="info">Defense Technology</div>
      </li>
      <li>
        <span class="title">Conference Reviewer</span>
        <div class="info">CVPR/ICCV/WACV/ECCV/ACM Multimedia</div>
        <div class="info">AAAI/NeurIPS/ICLR/ICRA</div>
        <div class="info">NAACL-HLT SRW 2021</div>
        <div class="info">ACL 2020 Student Research Workshop</div>
        <div class="info">CVPR 2020 AI for Content Creation Workshop</div>
      </li>
    </ul>
  </div> -->

</div>


<!--
	forked from Junwei Liang's production
-->
</body>
</html>
